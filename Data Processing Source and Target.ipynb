{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle, h5py, os\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import utils as ut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Laoding the labels of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_out = open('labels_subjects.pkl',\"rb\")\n",
    "temp = pickle.load(pickle_out)\n",
    "labels = np.array(temp[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initalizations\n",
    "filename = 'All_activity_instances_data.h5'\n",
    "path_to_data = # Data path of the created dictionary\n",
    "\n",
    "# dataset information and source activities \n",
    "total_subjects = np.unique(temp[1]).shape[0] \n",
    "total_Activities = 33\n",
    "num_source_activities =  int(np.round(0.8*total_Activities)) # number of activities used for training source network\n",
    "num_target_activities = total_Activities - num_source_activities # number of activities used for traget network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the osurce and target classes\n",
    "pickle_out = open('source_activities.pkl',\"rb\")\n",
    "src_act_array = pickle.load(pickle_out)\n",
    "trg_act_array = np.arange(total_Activities)[~np.isin(np.arange(total_Activities),src_act_array)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making the Training and Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "\n",
    "samples_per_class_train = 300\n",
    "samples_per_class_Val = 20 # it is assumed that the class samples are greater than this number\n",
    "\n",
    "\n",
    "total_samples_train = samples_per_class_train *src_act_array.shape[0]\n",
    "indices_array_train = np.zeros(total_samples_train)\n",
    "new_labels_train = np.zeros(total_samples_train)\n",
    "\n",
    "total_samples_Val = samples_per_class_Val *src_act_array.shape[0]\n",
    "indices_array_Val = np.zeros(total_samples_Val)\n",
    "new_labels_Val = np.zeros(total_samples_Val)\n",
    "\n",
    "\n",
    "\n",
    "start = 0\n",
    "end = start+ samples_per_class_train\n",
    "startv= 0 \n",
    "endv = start + samples_per_class_Val\n",
    "\n",
    "\n",
    "for i in range(src_act_array.shape[0]):\n",
    "    temp = np.where(labels == src_act_array[i])[0] # these are all the indices of that class\n",
    "    val_temp = np.random.choice(temp,samples_per_class_Val,replace = False)#now choose sample equal to sampel_per_class_Val\n",
    "    train_temp = temp[~np.isin(temp,val_temp)]\n",
    "    \n",
    "    if(train_temp.shape[0]<samples_per_class_train):\n",
    "        replace_bool = True\n",
    "    else:\n",
    "        replace_bool = False\n",
    "    indices_resampled = resample(train_temp,replace=replace_bool,n_samples=samples_per_class_train,random_state=42)\n",
    "    indices_array_train[start:end] = indices_resampled\n",
    "    new_labels_train[start:end] = src_act_array[i] \n",
    "    \n",
    "    indices_array_Val[startv:endv] = val_temp\n",
    "    new_labels_Val[startv:endv] = src_act_array[i] \n",
    "    \n",
    "    startv = endv\n",
    "    endv = startv+samples_per_class_Val\n",
    "    start = end\n",
    "    end = start+samples_per_class_train\n",
    "    \n",
    "indices_array_Val,new_labels_Val = ut.shuffle_indices(indices_array_Val,new_labels_Val)\n",
    "indices_array_train,new_labels_train = ut.shuffle_indices(indices_array_train,new_labels_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Indices_Train_Val.pkl', 'wb') as handle:\n",
    "    pickle.dump([indices_array_train,indices_array_Val,new_labels_train,new_labels_Val], handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select target support set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: The validation set is actually the support set and train here is the test set for the target.Just resusing the code so\n",
    "# not changing the notation\n",
    "\n",
    "total = 0\n",
    "for i in range(trg_act_array.shape[0]):\n",
    "    temp = np.where(labels == trg_act_array[i])[0] # these are all the indices of that class\n",
    "    total = total+temp.shape[0]\n",
    "\n",
    "samples_per_class_Val = 5 # it is assumed that the class samples are greater than this number\n",
    "total_samples_Val = samples_per_class_Val *trg_act_array.shape[0]\n",
    "indices_array_Val = np.zeros(total_samples_Val)\n",
    "new_labels_Val = np.zeros(total_samples_Val)\n",
    "\n",
    " \n",
    "\n",
    "total_samples_train = total - total_samples_Val\n",
    "indices_array_train = np.zeros(total_samples_train)\n",
    "new_labels_train = np.zeros(total_samples_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "start = 0\n",
    "startv= 0 \n",
    "endv = startv+ samples_per_class_Val\n",
    "\n",
    "\n",
    "for i in range(trg_act_array.shape[0]):\n",
    "\n",
    "    temp = np.where(labels == trg_act_array[i])[0] # these are all the indices of that class\n",
    "    val_temp = np.random.choice(temp,samples_per_class_Val,replace = False)\n",
    "    train_temp = temp[~np.isin(temp,val_temp)]\n",
    "\n",
    "\n",
    "    end = start+train_temp.shape[0]\n",
    "#     print(i,start,end,train_temp.shape[0])\n",
    "    indices_array_train[start:end] = train_temp[:]\n",
    "    new_labels_train[start:end] = trg_act_array[i] \n",
    "\n",
    "    indices_array_Val[startv:endv] = val_temp\n",
    "    new_labels_Val[startv:endv] = trg_act_array[i] \n",
    "\n",
    "    startv = endv\n",
    "    endv = startv+samples_per_class_Val\n",
    "    start = end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_array_supp,new_labels_supp = ut.shuffle_indices(indices_array_Val,new_labels_Val)\n",
    "indices_array_test,new_labels_test = ut.shuffle_indices(indices_array_train,new_labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Indices_trg_Test_supp.pkl', 'wb') as handle:\n",
    "    pickle.dump([indices_array_test,indices_array_supp,new_labels_test,new_labels_supp], handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfgpu",
   "language": "python",
   "name": "tfgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
