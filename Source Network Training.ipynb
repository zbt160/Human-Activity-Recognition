{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle,h5py,os,keras,json, os, argparse, imp\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import utils as ut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intializations \n",
    "path_to_data = # Data path of the created dictionary\n",
    "filename = 'All_activity_instances_data.h5'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_out = open('Indices_Train_Val.pkl',\"rb\")\n",
    "temp = pickle.load(pickle_out) # indices of validation and test set\n",
    "pickle_out.close()\n",
    "indices_array_train = temp[0]\n",
    "indices_array_Val = temp[1]\n",
    "new_labels_train = temp[2]\n",
    "new_labels_Val = temp[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = h5py.File(os.path.join(path_to_data,filename), 'r') \n",
    "X_data = data_file['X']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.zeros((indices_array_train.shape[0],X_data.shape[1],X_data.shape[2]))\n",
    "X_Val = np.zeros((indices_array_Val.shape[0],X_data.shape[1],X_data.shape[2]))\n",
    "\n",
    "for i in range(indices_array_train.shape[0]):\n",
    "    X_train[i,:,:] = X_data[indices_array_train[i],:,:]\n",
    "for i in range(indices_array_Val.shape[0]):\n",
    "    X_Val[i,:,:] = X_data[indices_array_Val[i],:,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = ut.convert_one_hot(new_labels_train)\n",
    "y_Val = ut.convert_one_hot(new_labels_Val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Source Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelPath = \"./models/\"\n",
    "modelName = \"Stacked_LSTM_classifier\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(inp_shp,num_classes):\n",
    "    inputs = keras.Input(shape=inp_shp, name=\"digits\")\n",
    "    x1 = keras.layers.LSTM(50,return_sequences = False, activation=\"relu\", name=\"LSTM_1\" )(inputs)\n",
    "#     x = keras.layers.LSTM(64,return_sequences = False, activation=\"relu\", name=\"LSTM_2\" )(x)\n",
    "#     x = keras.layers.Dense(32, activation=\"relu\", name=\"dense_1\")(x)\n",
    "    x2 = keras.layers.Dense(num_classes, name=\"dense_2\")(x1)\n",
    "    outputs = keras.layers.Activation('softmax',name=\"activation\")(x2)\n",
    "    functional_model = keras.Model(inputs=inputs, outputs=outputs, name=\"Stacked_LSTM\")\n",
    "    return functional_model\n",
    "\n",
    "def get_model_2(inp_shp,num_classes):\n",
    "    model = model_check(inp_shp)\n",
    "    inputs = keras.Input(shape=inp_shp, name=\"digits\")\n",
    "    features = model(inputs)\n",
    "    classifier = keras.layers.Dense(num_classes,use_bias = False)(features)\n",
    "    outputs = keras.layers.Activation('softmax',name=\"activation\")(classifier)\n",
    "    functional_model = keras.Model(inputs=inputs, outputs=outputs, name=\"Stacked_LSTM\")\n",
    "    return functional_model\n",
    "\n",
    "\n",
    "def model_check(input_shape):\n",
    "#     inp = Input(input_shape)\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.LSTM(128,dropout = 0.2,return_sequences = True,input_shape = input_shape))\n",
    "    model.add(keras.layers.LSTM(100,dropout = 0.2,return_sequences= False,input_shape = input_shape))\n",
    "    model.add(keras.layers.Dense(64))\n",
    "    model.add(keras.layers.Dropout(0.2))\n",
    "    model.add(keras.layers.Dense(40))\n",
    "    model.add(keras.layers.Dropout(0.2))\n",
    "#     model.add(keras.layers.Activation('softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Stacked_LSTM\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "digits (InputLayer)          (None, 250, 117)          0         \n",
      "_________________________________________________________________\n",
      "sequential_4 (Sequential)    (None, 40)                226616    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 26)                1040      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 26)                0         \n",
      "=================================================================\n",
      "Total params: 227,656\n",
      "Trainable params: 227,656\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "source_model = get_model_2((250,117),26)\n",
    "# source_model = model_check((250,117))\n",
    "source_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(+) Saving model: Stacked_LSTM_classifier\n"
     ]
    }
   ],
   "source": [
    "from keras.backend.tensorflow_backend import set_session\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "sess = tf.Session(config=config)\n",
    "set_session(sess)  # set this TensorFlow session as the default session for Keras\n",
    "\n",
    "print('(+) Saving model: '+modelName)\n",
    "json_string = source_model.to_json()\n",
    "open(os.path.join(modelPath, modelName+'.json'), 'w').write(json_string)\n",
    "ad =keras.optimizers.Adam(lr = 0.01)\n",
    "source_model.compile(loss=keras.losses.CategoricalCrossentropy(), optimizer=ad, metrics=['acc'])\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "checkpointer = ModelCheckpoint(filepath=os.path.join(modelPath,modelName+'2.wgt'), \n",
    "                                verbose=1, \n",
    "                                save_best_only=True,monitor = 'val_acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source_model.load_weights(os.path.join(modelPath, modelName+'1.wgt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7800 samples, validate on 520 samples\n",
      "Epoch 1/10\n",
      "7800/7800 [==============================] - 46s 6ms/step - loss: 1.5488 - acc: 0.4917 - val_loss: 0.7451 - val_acc: 0.7462\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.74615, saving model to ./models/Stacked_LSTM_classifier2.wgt\n",
      "Epoch 2/10\n",
      "7800/7800 [==============================] - 46s 6ms/step - loss: 0.9552 - acc: 0.6660 - val_loss: 0.4739 - val_acc: 0.8096\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.74615 to 0.80962, saving model to ./models/Stacked_LSTM_classifier2.wgt\n",
      "Epoch 3/10\n",
      "7800/7800 [==============================] - 46s 6ms/step - loss: 0.7095 - acc: 0.7646 - val_loss: 0.3452 - val_acc: 0.8942\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.80962 to 0.89423, saving model to ./models/Stacked_LSTM_classifier2.wgt\n",
      "Epoch 4/10\n",
      "7800/7800 [==============================] - 45s 6ms/step - loss: 0.4985 - acc: 0.8424 - val_loss: 0.2048 - val_acc: 0.9269\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.89423 to 0.92692, saving model to ./models/Stacked_LSTM_classifier2.wgt\n",
      "Epoch 5/10\n",
      "7800/7800 [==============================] - 45s 6ms/step - loss: 0.4590 - acc: 0.8546 - val_loss: 0.1798 - val_acc: 0.9423\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.92692 to 0.94231, saving model to ./models/Stacked_LSTM_classifier2.wgt\n",
      "Epoch 6/10\n",
      "7800/7800 [==============================] - 46s 6ms/step - loss: 0.3299 - acc: 0.9032 - val_loss: 0.1275 - val_acc: 0.9519\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.94231 to 0.95192, saving model to ./models/Stacked_LSTM_classifier2.wgt\n",
      "Epoch 7/10\n",
      "7800/7800 [==============================] - 46s 6ms/step - loss: 0.3318 - acc: 0.9036 - val_loss: 0.1063 - val_acc: 0.9692\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.95192 to 0.96923, saving model to ./models/Stacked_LSTM_classifier2.wgt\n",
      "Epoch 8/10\n",
      "7800/7800 [==============================] - 45s 6ms/step - loss: 0.2847 - acc: 0.9204 - val_loss: 0.0652 - val_acc: 0.9808\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.96923 to 0.98077, saving model to ./models/Stacked_LSTM_classifier2.wgt\n",
      "Epoch 9/10\n",
      "7800/7800 [==============================] - 46s 6ms/step - loss: 0.2782 - acc: 0.9229 - val_loss: 0.0682 - val_acc: 0.9846\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.98077 to 0.98462, saving model to ./models/Stacked_LSTM_classifier2.wgt\n",
      "Epoch 10/10\n",
      "7800/7800 [==============================] - 45s 6ms/step - loss: 0.2260 - acc: 0.9359 - val_loss: 0.0889 - val_acc: 0.9769\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.98462\n"
     ]
    }
   ],
   "source": [
    "fitlog = source_model.fit(X_train,y_train,batch_size = 64,epochs=10, verbose=1, \n",
    "                    callbacks=[checkpointer],\n",
    "                    shuffle = \"batch\",validation_data = (X_Val,y_Val))\n",
    "source_model.save_weights(filepath=os.path.join(modelPath,modelName+'1lastepoch.wgt'), overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained = keras.Model(\n",
    "    source_model.inputs, source.layers[-1].input, name=\"pretrained_model\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(117), Dimension(200)])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_model.layers[-2].weights[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source_model.predict(X_Val)\n",
    "w_emp = source_model.layers[-2].weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 26)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_model.layers[-2].get_weights()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Activation' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-8d6e8a2a9e46>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msource_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_Val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'Activation' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "source_model.layers[-1].predict(X_Val).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfgpu",
   "language": "python",
   "name": "tfgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
