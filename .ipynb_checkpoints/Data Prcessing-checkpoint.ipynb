{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Zaid Bin Tariq\n",
    "\n",
    "Date: 2/27/2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook converts the raw data into training and testing set to be used for the neural network \n",
    "\n",
    "Data output might vary depending upon how the activity recognition problem is seen.\n",
    "\n",
    "Possibily another notebook in future might be made for different types of data splits for the human activity recognition problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle,os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will load the data was combined into a dictionary/lists for easy access. The following code is using the realDisp data and assumes that it was already split into a dictionary earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = 'D:/RPI_big/zbt/Reseach/Siamese learning/activity_recog'# Data path of the created dictionary\n",
    "dictionary_filename = \"All_data.pkl\"\n",
    "pickle_out = open(os.path.join(path_to_data,dictionary_filename),\"rb\")\n",
    "dictionary = pickle.load(pickle_out) # dictionary contains the data\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_subjects = len(dictionary) \n",
    "total_Activities = 33\n",
    "num_source_activities =  int(np.round(0.8*total_Activities)) # number of activities used for training source network\n",
    "num_target_activities = total_Activities - num_source_activities # number of activities used for traget network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_act_array = np.random.choice(np.arange(total_Activities),size = num_source_activities,replace = False)\n",
    "trg_act_array = np.arange(total_Activities)[~np.isin(np.arange(total_Activities),src_act_array)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_complete_data(data_dict,activities_arr,time_step = 250):\n",
    "    # Combines the data by activity and labels them\n",
    "    #output = (num_examples, timestep,117),labels\n",
    "    ln = activities_arr.shape[0]\n",
    "    label_combined = []\n",
    "    sub = 0\n",
    "    first = True\n",
    "    for act_num in activities_arr:\n",
    "        \n",
    "        for inst in range(len(data_dict[sub][act_num])):\n",
    "            brk = 1\n",
    "            start = 0\n",
    "            end = start+time_step\n",
    "            if(data_dict[sub][act_num][inst].shape[0]< time_step):\n",
    "                continue\n",
    "            while(brk):\n",
    "                if(end>data_dict[sub][act_num][inst].shape[0]):\n",
    "                    end = data_dict[sub][act_num][inst].shape[0]\n",
    "                    start = end-time_step\n",
    "                    brk = 0\n",
    "                    \n",
    "                data_append = data_dict[sub][act_num][inst][start:end,:]\n",
    "#                 print(act_num,data_append.shape,data_dict[sub][act_num][inst].shape[0],end)\n",
    "                if(first == True):\n",
    "                    data_combined = data_append[np.newaxis] \n",
    "                    first = False\n",
    "                else:\n",
    "                    data_combined = np.append(data_combined,data_append[np.newaxis],axis = 0)\n",
    "                label_combined.append(act_num)\n",
    "                start = end\n",
    "                end = end+time_step\n",
    "    first = True\n",
    "    if(sub == 0):\n",
    "        all_data_combined  = data_combined\n",
    "    else:\n",
    "        all_data_combined = np.append(all_data_combined,data_combined,axis = 0)\n",
    "    return all_data_combined,label_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = get_complete_data(dictionary,src_act_array,time_step = 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 250, 117)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = 0\n",
    "act_num = 10\n",
    "inst = 0\n",
    "dictionary[sub][act_num][inst].shape\n",
    "start = 0\n",
    "time_step = 250\n",
    "end = start+250\n",
    "\n",
    "for inst in range(len(dictionary[sub][act_num])):\n",
    "    brk = 1\n",
    "    while(brk):\n",
    "        if(end>dictionary[sub][act_num][inst].shape[0]):\n",
    "            end = dictionary[sub][act_num][inst].shape[0]\n",
    "            start = end-time_step\n",
    "            brk = 0\n",
    "        data_append = dictionary[sub][act_num][inst][start:end,:]\n",
    "        if(start == 0):\n",
    "            data_combined = data_append[np.newaxis] \n",
    "        else:\n",
    "            data_combined = np.append(data_combined,data_append[np.newaxis],axis = 0)\n",
    "        start = end\n",
    "        end = end+time_step\n",
    "if(sub == 0)\n",
    "    all_data_combined  = data_combined\n",
    "else:\n",
    "    all_data_combined = np.append(all_data_combined,data_combined,axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((250, 117), (6, 250, 117))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_append.shape,data_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_combined = data_append[np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 250, 117)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 250, 117)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.append(data_combined,data_append[np.newaxis],axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfgpu",
   "language": "python",
   "name": "tfgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
