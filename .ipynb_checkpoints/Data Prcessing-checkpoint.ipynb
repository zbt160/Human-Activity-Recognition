{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Zaid Bin Tariq\n",
    "\n",
    "Date: 2/27/2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook converts the raw data into training and testing set to be used for the neural network \n",
    "\n",
    "Data output might vary depending upon how the activity recognition problem is seen.\n",
    "\n",
    "Possibily another notebook in future might be made for different types of data splits for the human activity recognition problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle,os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import utils as ut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will load the data was combined into a dictionary/lists for easy access. The following code is using the realDisp data and assumes that it was already split into a dictionary earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = ''# Data path of the created dictionary\n",
    "dictionary_filename = \"All_data.pkl\"\n",
    "pickle_out = open(os.path.join(path_to_data,dictionary_filename),\"rb\")\n",
    "dictionary = pickle.load(pickle_out) # dictionary contains the data\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_subjects = len(dictionary) \n",
    "total_Activities = 33\n",
    "num_source_activities =  int(np.round(0.8*total_Activities)) # number of activities used for training source network\n",
    "num_target_activities = total_Activities - num_source_activities # number of activities used for traget network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_Activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Flip the comments in the box incase source_activities,pkl does not exist\n",
    "# src_act_array = np.random.choice(np.arange(total_Activities),size = num_source_activities,replace = False)\n",
    "# with open('source_activities.pkl', 'wb') as handle:\n",
    "#     pickle.dump(src_act_array, handle)\n",
    "pickle_out = open('source_activities.pkl',\"rb\")\n",
    "src_act_array = pickle.load(pickle_out)\n",
    "\n",
    "trg_act_array = np.arange(total_Activities)[~np.isin(np.arange(total_Activities),src_act_array)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filename = 'All_activity_instances_data.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "0 1\n",
      "0 2\n",
      "0 3\n",
      "0 4\n",
      "0 5\n",
      "0 6\n",
      "0 7\n",
      "0 8\n",
      "0 9\n",
      "0 10\n",
      "0 11\n",
      "0 12\n",
      "0 13\n",
      "0 14\n",
      "0 15\n",
      "0 16\n",
      "0 17\n",
      "0 18\n",
      "0 19\n",
      "0 20\n",
      "0 21\n",
      "0 22\n",
      "0 23\n",
      "0 24\n",
      "0 25\n",
      "0 26\n",
      "0 27\n",
      "0 28\n",
      "0 29\n",
      "0 30\n",
      "0 31\n",
      "0 32\n",
      "1 0\n",
      "1 1\n",
      "1 2\n",
      "1 3\n",
      "1 4\n",
      "1 5\n",
      "1 6\n",
      "1 7\n",
      "1 8\n",
      "1 9\n",
      "1 10\n",
      "1 11\n",
      "1 12\n",
      "1 13\n",
      "1 14\n",
      "1 15\n",
      "1 16\n",
      "1 17\n",
      "1 18\n",
      "1 19\n",
      "1 20\n",
      "1 21\n",
      "1 22\n",
      "1 23\n",
      "1 24\n",
      "1 25\n",
      "1 26\n",
      "1 27\n",
      "1 28\n",
      "1 29\n",
      "1 30\n",
      "1 31\n",
      "1 32\n",
      "2 0\n",
      "2 1\n",
      "2 2\n",
      "2 3\n",
      "2 4\n",
      "2 5\n",
      "2 6\n",
      "2 7\n",
      "2 8\n",
      "2 9\n",
      "2 10\n",
      "2 11\n",
      "2 12\n",
      "2 13\n",
      "2 14\n",
      "2 15\n",
      "2 16\n",
      "2 17\n",
      "2 18\n",
      "2 19\n",
      "2 20\n",
      "2 21\n",
      "2 22\n",
      "2 23\n",
      "2 24\n",
      "2 25\n",
      "2 26\n",
      "2 27\n",
      "2 28\n",
      "2 29\n",
      "2 30\n",
      "2 31\n",
      "2 32\n",
      "3 0\n",
      "3 1\n",
      "3 2\n",
      "3 3\n",
      "3 4\n",
      "3 5\n",
      "3 6\n",
      "3 7\n",
      "3 8\n",
      "3 9\n",
      "3 10\n",
      "3 11\n",
      "3 12\n",
      "3 13\n",
      "3 14\n",
      "3 15\n",
      "3 16\n",
      "3 17\n",
      "3 18\n",
      "3 19\n",
      "3 20\n",
      "3 21\n",
      "3 22\n",
      "3 23\n",
      "3 24\n",
      "3 25\n",
      "3 26\n",
      "3 27\n",
      "3 28\n",
      "3 29\n",
      "3 30\n",
      "3 31\n",
      "3 32\n",
      "4 0\n",
      "4 1\n",
      "4 2\n",
      "4 3\n",
      "4 4\n",
      "4 5\n",
      "4 6\n",
      "4 7\n",
      "4 8\n",
      "4 9\n",
      "4 10\n",
      "4 11\n",
      "4 12\n",
      "4 13\n",
      "4 14\n",
      "4 15\n",
      "4 16\n",
      "4 17\n",
      "4 18\n",
      "4 19\n",
      "4 20\n",
      "4 21\n",
      "4 22\n",
      "4 23\n",
      "4 24\n",
      "4 25\n",
      "4 26\n",
      "4 27\n",
      "4 28\n",
      "4 29\n",
      "4 30\n",
      "4 31\n",
      "4 32\n",
      "5 0\n",
      "5 1\n",
      "5 2\n",
      "5 3\n",
      "5 4\n",
      "5 5\n",
      "5 6\n",
      "5 7\n",
      "5 8\n",
      "5 9\n",
      "5 10\n",
      "5 11\n",
      "5 12\n",
      "5 13\n",
      "5 14\n",
      "5 15\n",
      "5 16\n",
      "5 17\n",
      "5 18\n",
      "5 19\n",
      "5 20\n",
      "5 21\n",
      "5 22\n",
      "5 23\n",
      "5 24\n",
      "5 25\n",
      "5 26\n",
      "5 27\n",
      "5 28\n",
      "5 29\n",
      "5 30\n",
      "5 31\n",
      "5 32\n",
      "6 0\n",
      "6 1\n",
      "6 2\n",
      "6 3\n",
      "6 4\n",
      "6 5\n",
      "6 6\n",
      "6 7\n",
      "6 8\n",
      "6 9\n",
      "6 10\n",
      "6 11\n",
      "6 12\n",
      "6 13\n",
      "6 14\n",
      "6 15\n",
      "6 16\n",
      "6 17\n",
      "6 18\n",
      "6 19\n",
      "6 20\n",
      "6 21\n",
      "6 22\n",
      "6 23\n",
      "6 24\n",
      "6 25\n",
      "6 26\n",
      "6 27\n",
      "6 28\n",
      "6 29\n",
      "6 30\n",
      "6 31\n",
      "6 32\n",
      "7 0\n",
      "7 1\n",
      "7 2\n",
      "7 3\n",
      "7 4\n",
      "7 5\n",
      "7 6\n",
      "7 7\n",
      "7 8\n",
      "7 9\n",
      "7 10\n",
      "7 11\n",
      "7 12\n",
      "7 13\n",
      "7 14\n",
      "7 15\n",
      "7 16\n",
      "7 17\n",
      "7 18\n",
      "7 19\n",
      "7 20\n",
      "7 21\n",
      "7 22\n",
      "7 23\n",
      "7 24\n",
      "7 25\n",
      "7 26\n",
      "7 27\n",
      "7 28\n",
      "7 29\n",
      "7 30\n",
      "7 31\n",
      "7 32\n",
      "8 0\n",
      "8 1\n",
      "8 2\n",
      "8 3\n",
      "8 4\n",
      "8 5\n",
      "8 6\n",
      "8 7\n",
      "8 8\n",
      "8 9\n",
      "8 10\n",
      "8 11\n",
      "8 12\n",
      "8 13\n",
      "8 14\n",
      "8 15\n",
      "8 16\n",
      "8 17\n",
      "8 18\n",
      "8 19\n",
      "8 20\n",
      "8 21\n",
      "8 22\n",
      "8 23\n",
      "8 24\n",
      "8 25\n",
      "8 26\n",
      "8 27\n",
      "8 28\n",
      "8 29\n",
      "8 30\n",
      "8 31\n",
      "8 32\n",
      "9 0\n",
      "9 1\n",
      "9 2\n",
      "9 3\n",
      "9 4\n",
      "9 5\n",
      "9 6\n",
      "9 7\n",
      "9 8\n",
      "9 9\n",
      "9 10\n",
      "9 11\n",
      "9 12\n",
      "9 13\n",
      "9 14\n",
      "9 15\n",
      "9 16\n",
      "9 17\n",
      "9 18\n",
      "9 19\n",
      "9 20\n",
      "9 21\n",
      "9 22\n",
      "9 23\n",
      "9 24\n",
      "9 25\n",
      "9 26\n",
      "9 27\n",
      "9 28\n",
      "9 29\n",
      "9 30\n",
      "9 31\n",
      "9 32\n",
      "10 0\n",
      "10 1\n",
      "10 2\n",
      "10 3\n",
      "10 4\n",
      "10 5\n",
      "10 6\n",
      "10 7\n",
      "10 8\n",
      "10 9\n",
      "10 10\n",
      "10 11\n",
      "10 12\n",
      "10 13\n",
      "10 14\n",
      "10 15\n",
      "10 16\n",
      "10 17\n",
      "10 18\n",
      "10 19\n",
      "10 20\n",
      "10 21\n",
      "10 22\n",
      "10 23\n",
      "10 24\n",
      "10 25\n",
      "10 26\n",
      "10 27\n",
      "10 28\n",
      "10 29\n",
      "10 30\n",
      "10 31\n",
      "10 32\n",
      "11 0\n",
      "11 1\n",
      "11 2\n",
      "11 3\n",
      "11 4\n",
      "11 5\n",
      "11 6\n",
      "11 7\n",
      "11 8\n",
      "11 9\n",
      "11 10\n",
      "11 11\n",
      "11 12\n",
      "11 13\n",
      "11 14\n",
      "11 15\n",
      "11 16\n",
      "11 17\n",
      "11 18\n",
      "11 19\n",
      "11 20\n",
      "11 21\n",
      "11 22\n",
      "11 23\n",
      "11 24\n",
      "11 25\n",
      "11 26\n",
      "11 27\n",
      "11 28\n",
      "11 29\n",
      "11 30\n",
      "11 31\n",
      "11 32\n",
      "12 0\n",
      "12 1\n",
      "12 2\n",
      "12 3\n",
      "12 4\n",
      "12 5\n",
      "12 6\n",
      "12 7\n",
      "12 8\n",
      "12 9\n",
      "12 10\n",
      "12 11\n",
      "12 12\n",
      "12 13\n",
      "12 14\n",
      "12 15\n",
      "12 16\n",
      "12 17\n",
      "12 18\n",
      "12 19\n",
      "12 20\n",
      "12 21\n",
      "12 22\n",
      "12 23\n",
      "12 24\n",
      "12 25\n",
      "12 26\n",
      "12 27\n",
      "12 28\n",
      "12 29\n",
      "12 30\n",
      "12 31\n",
      "12 32\n",
      "13 0\n",
      "13 1\n",
      "13 2\n",
      "13 3\n",
      "13 4\n",
      "13 5\n",
      "13 6\n",
      "13 7\n",
      "13 8\n",
      "13 9\n",
      "13 10\n",
      "13 11\n",
      "13 12\n",
      "13 13\n",
      "13 14\n",
      "13 15\n",
      "13 16\n",
      "13 17\n",
      "13 18\n",
      "13 19\n",
      "13 20\n",
      "13 21\n",
      "13 22\n",
      "13 23\n",
      "13 24\n",
      "13 25\n",
      "13 26\n",
      "13 27\n",
      "13 28\n",
      "13 29\n",
      "13 30\n",
      "13 31\n",
      "13 32\n",
      "14 0\n",
      "14 1\n",
      "14 2\n",
      "14 3\n",
      "14 4\n",
      "14 5\n",
      "14 6\n",
      "14 7\n",
      "14 8\n",
      "14 9\n",
      "14 10\n",
      "14 11\n",
      "14 12\n",
      "14 13\n",
      "14 14\n",
      "14 15\n",
      "14 16\n",
      "14 17\n",
      "14 18\n",
      "14 19\n",
      "14 20\n",
      "14 21\n",
      "14 22\n",
      "14 23\n",
      "14 24\n",
      "14 25\n",
      "14 26\n",
      "14 27\n",
      "14 28\n",
      "14 29\n",
      "14 30\n",
      "14 31\n",
      "14 32\n",
      "15 0\n",
      "15 1\n",
      "15 2\n",
      "15 3\n",
      "15 4\n",
      "15 5\n",
      "15 6\n",
      "15 7\n",
      "15 8\n",
      "15 9\n",
      "15 10\n",
      "15 11\n",
      "15 12\n",
      "15 13\n",
      "15 14\n",
      "15 15\n",
      "15 16\n",
      "15 17\n",
      "15 18\n",
      "15 19\n",
      "15 20\n",
      "15 21\n",
      "15 22\n",
      "15 23\n",
      "15 24\n",
      "15 25\n",
      "15 26\n",
      "15 27\n",
      "15 28\n",
      "15 29\n",
      "15 30\n",
      "15 31\n",
      "15 32\n",
      "16 0\n",
      "16 1\n",
      "16 2\n",
      "16 3\n",
      "16 4\n",
      "16 5\n",
      "16 6\n",
      "16 7\n",
      "16 8\n",
      "16 9\n",
      "16 10\n",
      "16 11\n",
      "16 12\n",
      "16 13\n",
      "16 14\n",
      "16 15\n",
      "16 16\n",
      "16 17\n",
      "16 18\n",
      "16 19\n",
      "16 20\n",
      "16 21\n",
      "16 22\n",
      "16 23\n",
      "16 24\n",
      "16 25\n",
      "16 26\n",
      "16 27\n",
      "16 28\n",
      "16 29\n",
      "16 30\n",
      "16 31\n",
      "16 32\n"
     ]
    }
   ],
   "source": [
    "temp = ut.get_complete_data2(dictionary,np.arange(0,total_Activities),path_to_data,'All_activity_instances_data.h5',50,time_step = 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('labels_subjects.pkl', 'wb') as handle:\n",
    "    pickle.dump(temp, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(temp[0],temp[1], test_size=0.2,random_state=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(temp[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from operator import itemgetter\n",
    "\n",
    "ob = Counter(labels)\n",
    "values = ob.values()\n",
    "values\n",
    "check = []\n",
    "for val in values:\n",
    "    check.append(val)\n",
    "\n",
    "check = np.array(check)\n",
    "class_total_samples = int(np.floor(np.mean(check[1:])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "spam_upsample = resample(temp_X,\n",
    "             replace=True,\n",
    "             n_samples=7,\n",
    "             random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "class_total_samples = 400\n",
    "data_file = h5py.File(os.path.join(path_to_data,filename), 'r') \n",
    "X_data = data_file['X']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(850, 250, 117)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data[np.where(labels == 2)[0],:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_samples = class_total_samples *src_act_array.shape[0]\n",
    "indices_array = np.zeros(total_samples)\n",
    "new_labels = np.zeros(total_samples)\n",
    "start = 0\n",
    "end = start+ class_total_samples\n",
    "\n",
    "\n",
    "for i in range(src_act_array.shape[0]):\n",
    "    temp = np.where(labels == src_act_array[i])[0]\n",
    "    if(temp.shape[0]<class_total_samples):\n",
    "        replace_bool = True\n",
    "    else:\n",
    "        replace_bool = False\n",
    "    indices_resampled = resample(temp,replace=replace_bool,n_samples=class_total_samples,random_state=42)\n",
    "    indices_array[start:end] = indices_resampled\n",
    "    new_labels[start:end] = src_act_array[i] \n",
    "    start = end\n",
    "    end = start+class_total_samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "indices_train, indices_Val, label_train, label_Val = train_test_split(indices_array,new_labels, test_size=0.2,random_state=25,shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.zeros((indices_train.shape[0],X_data.shape[1],X_data.shape[2]))\n",
    "X_Val = np.zeros((indices_Val.shape[0],X_data.shape[1],X_data.shape[2]))\n",
    "\n",
    "for i in range(indices_train.shape[0]):\n",
    "    X_train[i,:,:] = X_data[indices_train[i],:,:]\n",
    "for i in range(indices_Val.shape[0]):\n",
    "    X_Val[i,:,:] = X_data[indices_Val[i],:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# define example\n",
    "def convert_one_hot(arr):\n",
    "\n",
    "    values = arr\n",
    "    # integer encode\n",
    "    label_encoder = LabelEncoder()\n",
    "    integer_encoded = label_encoder.fit_transform(values)\n",
    "    # binary encode\n",
    "    onehot_encoder = OneHotEncoder(sparse=False)\n",
    "    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "    onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "    return onehot_encoded\n",
    "    # invert first example\n",
    "#     inverted = label_encoder.inverse_transform([argmax(onehot_encoded[0, :])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# onehot_encoded[2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = np.random.random((10,250,117))\n",
    "# y_train = convert_one_hot(np.arange(0,10))\n",
    "# X_Val = np.random.random((10,250,117))\n",
    "# y_Val = convert_one_hot(np.arange(0,10))\n",
    "\n",
    "\n",
    "y_train = convert_one_hot(label_train)\n",
    "y_Val = convert_one_hot(label_Val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2080, 26)"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_Val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model ML\n",
    "modelPath = \"./models/\"\n",
    "modelName = \"RNN_a1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_19 (LSTM)               (None, 50)                33600     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 26)                1326      \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 26)                0         \n",
      "=================================================================\n",
      "Total params: 34,926\n",
      "Trainable params: 34,926\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "(+) Saving model: RNN_a1\n"
     ]
    }
   ],
   "source": [
    "from keras.backend.tensorflow_backend import set_session\n",
    "from keras import optimizers\n",
    "import tensorflow as tf\n",
    "import json, os, argparse, imp\n",
    "\n",
    "# config = tf.ConfigProto()\n",
    "# config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "# config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "# sess = tf.Session(config=config)\n",
    "# set_session(sess)  # set this TensorFlow session as the default session for Keras\n",
    "# model_module = imp.load_source('model_module', os.path.join(modelPath, modelName+'.py'))\n",
    "model = model_check((250,117))\n",
    "model.summary()\n",
    "\n",
    "\n",
    "\n",
    "print('(+) Saving model: '+modelName)\n",
    "json_string = model.to_json()\n",
    "open(os.path.join(modelPath, modelName+'.json'), 'w').write(json_string)\n",
    "ad =optimizers.Adam(lr = 0.01)\n",
    "model.compile(loss='binary_crossentropy', optimizer=ad, metrics=['acc'])\n",
    "# model.load_weights(os.path.join(modelPath, modelName+substr+'.wgt'))\n",
    "# wait = input(\"Done\")\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "checkpointer = ModelCheckpoint(filepath=os.path.join(modelPath,modelName+'1.wgt'), \n",
    "                                verbose=1, \n",
    "                                save_best_only=True,monitor = 'val_acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8320 samples, validate on 2080 samples\n",
      "Epoch 1/10\n",
      "8320/8320 [==============================] - 9s 1ms/step - loss: 0.0811 - acc: 0.9735 - val_loss: 0.0303 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.99033, saving model to ./models/RNN_a11.wgt\n",
      "Epoch 2/10\n",
      "8320/8320 [==============================] - 8s 964us/step - loss: 0.0171 - acc: 0.9953 - val_loss: 0.0112 - val_acc: 0.9977\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.99033 to 0.99769, saving model to ./models/RNN_a11.wgt\n",
      "Epoch 3/10\n",
      "8320/8320 [==============================] - 8s 961us/step - loss: 0.0094 - acc: 0.9978 - val_loss: 0.0076 - val_acc: 0.9982\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.99769 to 0.99815, saving model to ./models/RNN_a11.wgt\n",
      "Epoch 4/10\n",
      "8320/8320 [==============================] - 8s 949us/step - loss: 0.0067 - acc: 0.9985 - val_loss: 0.0060 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.99815 to 0.99865, saving model to ./models/RNN_a11.wgt\n",
      "Epoch 5/10\n",
      "8320/8320 [==============================] - 8s 971us/step - loss: 0.0046 - acc: 0.9991 - val_loss: 0.0033 - val_acc: 0.9994\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.99865 to 0.99935, saving model to ./models/RNN_a11.wgt\n",
      "Epoch 6/10\n",
      "8320/8320 [==============================] - 8s 956us/step - loss: 0.0035 - acc: 0.9993 - val_loss: 0.0038 - val_acc: 0.9993\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.99935\n",
      "Epoch 7/10\n",
      "8320/8320 [==============================] - 8s 952us/step - loss: 0.0037 - acc: 0.9993 - val_loss: 0.0046 - val_acc: 0.9988\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.99935\n",
      "Epoch 8/10\n",
      "8320/8320 [==============================] - 8s 958us/step - loss: 0.0030 - acc: 0.9994 - val_loss: 0.0044 - val_acc: 0.9988\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.99935\n",
      "Epoch 9/10\n",
      "8320/8320 [==============================] - 8s 970us/step - loss: 0.0023 - acc: 0.9996 - val_loss: 0.0040 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.99935\n",
      "Epoch 10/10\n",
      "8320/8320 [==============================] - 8s 958us/step - loss: 0.0060 - acc: 0.9984 - val_loss: 0.0061 - val_acc: 0.9985\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.99935\n"
     ]
    }
   ],
   "source": [
    "fitlog = model.fit(X_train,y_train,batch_size = 256,epochs=10, verbose=1, \n",
    "                    callbacks=[checkpointer],\n",
    "                    shuffle = \"batch\",validation_data = (X_Val,y_Val))\n",
    "model.save_weights(filepath=os.path.join(modelPath,modelName+'1lastepoch.wgt'), overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten, Reshape\n",
    "\n",
    "def model_check(input_shape):\n",
    "#     inp = Input(input_shape)\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50,input_shape = input_shape))\n",
    "    model.add(Dense(26))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "#     encoded_l = model(inp)\n",
    "    \n",
    "    return model\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfgpu",
   "language": "python",
   "name": "tfgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
